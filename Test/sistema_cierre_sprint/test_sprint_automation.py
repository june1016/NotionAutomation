"""
Bater√≠a Completa de Tests - Automatizaci√≥n de Cierre de Sprint
=============================================================

Suite de testing integral que verifica todos los componentes cr√≠ticos del sistema
de automatizaci√≥n de cierre de sprint antes de la ejecuci√≥n en producci√≥n.
Incluye tests graduales desde conectividad hasta funcionalidad completa.

COMPONENTES TESTADOS:
1. Conectividad con todas las bases de datos
2. Detecci√≥n correcta de sprint actual  
3. Obtenci√≥n y an√°lisis de tareas del sprint
4. Agrupaci√≥n de tareas por persona
5. Filtrado de tareas para m√©tricas justas
6. Verificaci√≥n de registros de performance existentes

MODOS DE EJECUCI√ìN:
- python test_sprint_automation.py                    # Solo diagn√≥stico
- python test_sprint_automation.py --ejecutar-performance  # Crear performance
- python test_sprint_automation.py --test-completo         # Test completo + nuevo sprint

CR√çTICO:
Este test debe pasar completamente antes de ejecutar la automatizaci√≥n real.
Cualquier fallo debe investigarse y resolverse antes de proceder.
"""



import os
import sys
import logging
from datetime import datetime
from notion_client import Client
from dotenv import load_dotenv

# Agregar el directorio del script principal al path
sys.path.append(os.path.join(os.path.dirname(__file__), '../../Auto/sistema_cierre_sprint'))

# Importar funciones del script principal
from sprint_automation import (
    obtener_sprint_actual, 
    obtener_tareas_del_sprint, 
    agrupar_tareas_por_persona,
    filtrar_tareas_para_metricas,
    obtener_info_persona,
    obtener_area_persona,
    verificar_registro_existente
)

# Configuraci√≥n de logging para testing
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [TEST] - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("test_sprint_automation.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Cargar variables de entorno
load_dotenv()
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
DB_SPRINTS_ID = os.getenv("DB_SPRINTS_ID")
DB_TAREAS_ID = os.getenv("DB_TAREAS_ID") 
DB_PERSONAS_ID = os.getenv("DB_PERSONAS_ID")
DB_PERFORMANCE_ID = os.getenv("DB_PERFORMANCE_ID")

# Inicializar cliente de Notion
notion = Client(auth=NOTION_TOKEN)

def test_1_conexion_bases_datos():
    """Test 1: Verificar conexi√≥n con todas las bases de datos"""
    logger.info("üîç TEST 1: Verificando conexi√≥n con bases de datos...")
    
    bases_datos = {
        "Sprints": DB_SPRINTS_ID,
        "Tareas": DB_TAREAS_ID,
        "Personas": DB_PERSONAS_ID,
        "Performance": DB_PERFORMANCE_ID
    }
    
    resultados = {}
    
    for nombre, db_id in bases_datos.items():
        try:
            response = notion.databases.retrieve(db_id)
            resultados[nombre] = "‚úÖ CONEXI√ìN OK"
            logger.info(f"  ‚úÖ {nombre}: Conectado correctamente")
        except Exception as e:
            resultados[nombre] = f"‚ùå ERROR: {e}"
            logger.error(f"  ‚ùå {nombre}: Error de conexi√≥n - {e}")
    
    return resultados

def test_2_sprint_actual():
    """Test 2: Verificar detecci√≥n del sprint actual"""
    logger.info("üîç TEST 2: Verificando detecci√≥n de sprint actual...")
    
    try:
        sprint = obtener_sprint_actual()
        
        if sprint:
            nombre = sprint["properties"]["Nombre"]["title"][0]["text"]["content"]
            estado = sprint["properties"]["Estado"]["status"]["name"]
            fecha_inicio = sprint["properties"]["Fecha Inicio"]["date"]["start"]
            fecha_fin = sprint["properties"]["Fecha Fin"]["date"]["start"]
            
            logger.info(f"  ‚úÖ Sprint actual detectado: {nombre}")
            logger.info(f"  üìÖ Fecha inicio: {fecha_inicio}")
            logger.info(f"  üìÖ Fecha fin: {fecha_fin}")
            logger.info(f"  üìä Estado: {estado}")
            
            return {
                "status": "‚úÖ SUCCESS",
                "sprint_id": sprint["id"],
                "nombre": nombre,
                "estado": estado,
                "fecha_inicio": fecha_inicio,
                "fecha_fin": fecha_fin
            }
        else:
            logger.error("  ‚ùå No se detect√≥ ning√∫n sprint actual")
            return {"status": "‚ùå ERROR", "message": "No hay sprint actual"}
            
    except Exception as e:
        logger.error(f"  ‚ùå Error al obtener sprint actual: {e}")
        return {"status": "‚ùå ERROR", "message": str(e)}

def test_3_tareas_sprint(sprint_id):
    """Test 3: Verificar obtenci√≥n de tareas del sprint"""
    logger.info("üîç TEST 3: Verificando obtenci√≥n de tareas del sprint...")
    
    try:
        tareas = obtener_tareas_del_sprint(sprint_id)
        
        logger.info(f"  üìä Total de tareas encontradas: {len(tareas)}")
        
        # Analizar distribuci√≥n de tareas
        estados = {}
        prioridades = {}
        tareas_problematicas = []
        
        for i, tarea in enumerate(tareas):
            try:
                props = tarea["properties"]
                
                # Contar estados - MANEJO SEGURO DE None
                estado_prop = props.get("Estado") or {}
                status_prop = estado_prop.get("status") or {}
                estado = status_prop.get("name") or "Sin estado"
                estados[estado] = estados.get(estado, 0) + 1
                
                # Contar prioridades - MANEJO SEGURO DE None
                prioridad_prop = props.get("Prioridad") or {}
                select_prop = prioridad_prop.get("select") or {}
                prioridad = select_prop.get("name") or "Sin prioridad"
                prioridades[prioridad] = prioridades.get(prioridad, 0) + 1
                
            except Exception as e:
                # Registrar tareas problem√°ticas pero continuar
                nombre_tarea = "Sin nombre"
                try:
                    title_prop = props.get("Nombre") or {}
                    title_list = title_prop.get("title") or []
                    if title_list:
                        nombre_tarea = title_list[0].get("text", {}).get("content", "Sin nombre")
                except:
                    pass
                
                tareas_problematicas.append({
                    "indice": i,
                    "nombre": nombre_tarea,
                    "error": str(e)
                })
                
                # Contar como "Error en datos"
                estados["Error en datos"] = estados.get("Error en datos", 0) + 1
                prioridades["Error en datos"] = prioridades.get("Error en datos", 0) + 1
        
        logger.info("  üìà Distribuci√≥n por estados:")
        for estado, count in estados.items():
            logger.info(f"    - {estado}: {count}")
        
        logger.info("  üéØ Distribuci√≥n por prioridades:")
        for prioridad, count in prioridades.items():
            logger.info(f"    - {prioridad}: {count}")
        
        if tareas_problematicas:
            logger.warning(f"  ‚ö†Ô∏è Se encontraron {len(tareas_problematicas)} tareas con datos problem√°ticos:")
            for problema in tareas_problematicas[:5]:  # Mostrar solo las primeras 5
                logger.warning(f"    - Tarea {problema['indice']}: {problema['nombre']} - {problema['error']}")
            if len(tareas_problematicas) > 5:
                logger.warning(f"    ... y {len(tareas_problematicas) - 5} m√°s")
        
        return {
            "status": "‚úÖ SUCCESS",
            "total_tareas": len(tareas),
            "estados": estados,
            "prioridades": prioridades,
            "tareas_problematicas": len(tareas_problematicas),
            "tareas": tareas
        }
        
    except Exception as e:
        logger.error(f"  ‚ùå Error al obtener tareas: {e}")
        return {"status": "‚ùå ERROR", "message": str(e)}

def test_4_agrupacion_personas(tareas):
    """Test 4: Verificar agrupaci√≥n de tareas por persona"""
    logger.info("üîç TEST 4: Verificando agrupaci√≥n de tareas por persona...")
    
    try:
        personas, tareas_sin_asignar = agrupar_tareas_por_persona(tareas)
        
        logger.info(f"  üë• Personas con tareas asignadas: {len(personas)}")
        logger.info(f"  ‚ö†Ô∏è Tareas sin asignar: {len(tareas_sin_asignar)}")
        
        # Obtener nombres de personas y estad√≠sticas
        estadisticas_personas = {}
        
        for persona_id, tareas_persona in personas.items():
            try:
                persona_info = obtener_info_persona(persona_id)
                if persona_info:
                    nombre_prop = persona_info["properties"].get("Nombre") or {}
                    title_list = nombre_prop.get("title") or []
                    nombre = title_list[0].get("text", {}).get("content", "Sin nombre") if title_list else "Sin nombre"
                    area = obtener_area_persona(persona_info)
                else:
                    nombre = f"Persona {persona_id[:8]}"
                    area = "Error al obtener"
                
                estadisticas_personas[nombre] = {
                    "id": persona_id,
                    "area": area,
                    "total_tareas": len(tareas_persona),
                    "tareas": tareas_persona
                }
                
                # logger.info(f"    - {nombre} ({area}): {len(tareas_persona)} tareas")
                
                # POR ESTO:
                if area != "Sin departamento asignado":
                    logger.info(f"    - {nombre} ({area}): {len(tareas_persona)} tareas")
                else:
                    logger.info(f"    - {nombre}: {len(tareas_persona)} tareas")  # Sin mostrar √°rea problem√°tica
                
            except Exception as e:
                logger.warning(f"    - Persona {persona_id}: Error al obtener info - {e}")
                # Agregar entrada b√°sica para continuar testing
                estadisticas_personas[f"Persona_{persona_id[:8]}"] = {
                    "id": persona_id,
                    "area": "Error",
                    "total_tareas": len(tareas_persona),
                    "tareas": tareas_persona
                }
        
        return {
            "status": "‚úÖ SUCCESS",
            "total_personas": len(personas),
            "tareas_sin_asignar": len(tareas_sin_asignar),
            "estadisticas": estadisticas_personas
        }
        
    except Exception as e:
        logger.error(f"  ‚ùå Error en agrupaci√≥n: {e}")
        return {"status": "‚ùå ERROR", "message": str(e)}

def test_extra_inspeccion_tareas(tareas):
    """Test EXTRA: Inspecci√≥n detallada de algunas tareas para diagn√≥stico"""
    logger.info("üîç TEST EXTRA: Inspeccionando estructura de tareas...")
    
    try:
        # Inspeccionar las primeras 3 tareas
        for i, tarea in enumerate(tareas[:3]):
            logger.info(f"  üìÑ TAREA {i+1}:")
            
            try:
                # Mostrar ID
                logger.info(f"    ID: {tarea.get('id', 'Sin ID')}")
                
                # Mostrar propiedades disponibles
                props = tarea.get("properties", {})
                logger.info(f"    Propiedades disponibles: {list(props.keys())}")
                
                # Inspeccionar propiedades cr√≠ticas
                propiedades_criticas = ["Nombre", "Estado", "Prioridad", "Carga", "Carga Completada", "Completada"]
                
                for prop_name in propiedades_criticas:
                    prop_value = props.get(prop_name)
                    if prop_value is None:
                        logger.info(f"    {prop_name}: None")
                    elif isinstance(prop_value, dict):
                        logger.info(f"    {prop_name}: {type(prop_value).__name__} - Keys: {list(prop_value.keys())}")
                        # Mostrar valor espec√≠fico si es simple
                        if len(str(prop_value)) < 100:
                            logger.info(f"      Valor: {prop_value}")
                    else:
                        logger.info(f"    {prop_name}: {type(prop_value).__name__} - {prop_value}")
                
            except Exception as e:
                logger.error(f"    ‚ùå Error inspeccionando tarea {i+1}: {e}")
        
        return {"status": "‚úÖ SUCCESS", "message": "Inspecci√≥n completada"}
        
    except Exception as e:
        logger.error(f"  ‚ùå Error en inspecci√≥n: {e}")
        return {"status": "‚ùå ERROR", "message": str(e)}

def test_5_filtrado_metricas(estadisticas_personas):
    """Test 5: Verificar filtrado de tareas para m√©tricas"""
    logger.info("üîç TEST 5: Verificando filtrado de tareas para m√©tricas...")
    
    try:
        resultados_filtrado = {}
        
        for nombre, data in estadisticas_personas.items():
            try:
                tareas_persona = data["tareas"]
                
                # Aplicar filtrado
                tareas_para_metricas, tareas_excluidas, stats = filtrar_tareas_para_metricas(tareas_persona)
                
                resultados_filtrado[nombre] = {
                    "total_original": stats["total_original"],
                    "para_metricas": stats["total_para_metricas"],
                    "excluidas": stats["total_excluidas"],
                    "imprevistas_completadas": stats["imprevistas_completadas_incluidas"]
                }
                
                logger.info(f"  üë§ {nombre}:")
                logger.info(f"    - Original: {stats['total_original']}")
                logger.info(f"    - Para m√©tricas: {stats['total_para_metricas']}")
                logger.info(f"    - Excluidas: {stats['total_excluidas']}")
                logger.info(f"    - Imprevistas completadas: {stats['imprevistas_completadas_incluidas']}")
                
                if tareas_excluidas:
                    logger.info(f"    - Tareas excluidas:")
                    for excluida in tareas_excluidas[:3]:  # Mostrar solo las primeras 3
                        logger.info(f"      * {excluida['nombre']} ({excluida['razon']})")
                    if len(tareas_excluidas) > 3:
                        logger.info(f"      ... y {len(tareas_excluidas) - 3} m√°s")
                        
            except Exception as e:
                logger.error(f"    ‚ùå Error al procesar {nombre}: {e}")
                resultados_filtrado[nombre] = {
                    "error": str(e)
                }
        
        return {
            "status": "‚úÖ SUCCESS",
            "resultados": resultados_filtrado
        }
        
    except Exception as e:
        logger.error(f"  ‚ùå Error en filtrado: {e}")
        return {"status": "‚ùå ERROR", "message": str(e)}

def test_6_verificar_performance_existente(estadisticas_personas, sprint_id):
    """Test 6: Verificar si ya existen registros de performance"""
    logger.info("üîç TEST 6: Verificando registros de performance existentes...")
    
    try:
        registros_existentes = {}
        
        for nombre, data in estadisticas_personas.items():
            persona_id = data["id"]
            existe = verificar_registro_existente(persona_id, sprint_id)
            
            registros_existentes[nombre] = existe
            
            if existe:
                logger.warning(f"  ‚ö†Ô∏è {nombre}: YA TIENE registro de performance")
            else:
                logger.info(f"  ‚úÖ {nombre}: Sin registro previo")
        
        return {
            "status": "‚úÖ SUCCESS",
            "registros_existentes": registros_existentes
        }
        
    except Exception as e:
        logger.error(f"  ‚ùå Error al verificar performance: {e}")
        return {"status": "‚ùå ERROR", "message": str(e)}

def ejecutar_tests_completos():
    """Ejecuta todos los tests en secuencia"""
    logger.info("üöÄ INICIANDO BATER√çA COMPLETA DE TESTS")
    logger.info("=" * 60)
    
    resultados = {}
    
    # Test 1: Conexi√≥n
    resultados["test_1"] = test_1_conexion_bases_datos()
    
    # Test 2: Sprint actual
    resultado_sprint = test_2_sprint_actual()
    resultados["test_2"] = resultado_sprint
    
    if resultado_sprint["status"] == "‚úÖ SUCCESS":
        sprint_id = resultado_sprint["sprint_id"]
        
        # Test 3: Tareas
        resultado_tareas = test_3_tareas_sprint(sprint_id)
        resultados["test_3"] = resultado_tareas
        
        if resultado_tareas["status"] == "‚úÖ SUCCESS":
            tareas = resultado_tareas["tareas"]
            
            # Test EXTRA: Inspecci√≥n detallada
            resultados["test_extra"] = test_extra_inspeccion_tareas(tareas)
            
            # Test 4: Agrupaci√≥n
            resultado_agrupacion = test_4_agrupacion_personas(tareas)
            resultados["test_4"] = resultado_agrupacion
            
            if resultado_agrupacion["status"] == "‚úÖ SUCCESS":
                estadisticas = resultado_agrupacion["estadisticas"]
                
                # Test 5: Filtrado
                resultados["test_5"] = test_5_filtrado_metricas(estadisticas)
                
                # Test 6: Performance existente
                resultados["test_6"] = test_6_verificar_performance_existente(estadisticas, sprint_id)
    
    # Resumen final
    logger.info("=" * 60)
    logger.info("üìã RESUMEN DE TESTS:")
    
    for test_name, resultado in resultados.items():
        if isinstance(resultado, dict) and "status" in resultado:
            logger.info(f"  {test_name}: {resultado['status']}")
        else:
            logger.info(f"  {test_name}: {resultado}")
    
    return resultados

def mostrar_instrucciones_siguientes():
    """Muestra instrucciones para el siguiente paso"""
    logger.info("=" * 60)
    logger.info("üìù PR√ìXIMOS PASOS RECOMENDADOS:")
    logger.info("")
    logger.info("1. Si todos los tests pasaron ‚úÖ:")
    logger.info("   - Ejecutar: python test_sprint_automation.py --ejecutar-performance")
    logger.info("   - Esto crear√° los registros de performance SOLO")
    logger.info("")
    logger.info("2. Si hay registros existentes:")
    logger.info("   - Limpiar tabla Performance manualmente")
    logger.info("   - Volver a ejecutar tests")
    logger.info("")
    logger.info("3. Para test completo (incluye crear Sprint 81):")
    logger.info("   - Ejecutar: python test_sprint_automation.py --test-completo")
    logger.info("")
    logger.info("‚ö†Ô∏è  IMPORTANTE: Este es entorno de PRUEBAS")
    logger.info("   Revisa logs detallados en: test_sprint_automation.log")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--ejecutar-performance":
            # Ejecutar solo creaci√≥n de performance
            from sprint_automation import ejecutar_cierre_sprint
            logger.info("üî• EJECUTANDO CREACI√ìN DE PERFORMANCE...")
            resultado = ejecutar_cierre_sprint()
            if resultado:
                logger.info("‚úÖ Performance creado exitosamente")
            else:
                logger.error("‚ùå Error al crear performance")
                
        elif sys.argv[1] == "--test-completo":
            # Test completo incluyendo creaci√≥n de sprint
            logger.info("üî• EJECUTANDO TEST COMPLETO...")
            ejecutar_tests_completos()
            
            from sprint_automation import ejecutar_cierre_sprint
            resultado = ejecutar_cierre_sprint()
            if resultado:
                logger.info("‚úÖ TEST COMPLETO EXITOSO")
            else:
                logger.error("‚ùå TEST COMPLETO FALL√ì")
        else:
            logger.error("‚ùå Argumento no reconocido")
    else:
        # Solo ejecutar tests de diagn√≥stico
        ejecutar_tests_completos()
        mostrar_instrucciones_siguientes()